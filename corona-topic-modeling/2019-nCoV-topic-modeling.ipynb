{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling of Social Media Data regarding the 2019-nCoV Pandemic.\n",
    "#### Data source: Twitter\n",
    "#### Last data update: 01/28/2020 - 16:17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/zero/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/zero/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import gensim\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pyLDAvis.gensim\n",
    "import random\n",
    "import spacy\n",
    "from gensim import corpora\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "spacy.load('en_core_web_sm')\n",
    "from spacy.lang.en import English\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    @lookner I taught a class in college on the co...\n",
       "1                   this corona virus is scary as hell\n",
       "2                     new corona virus is pretty scary\n",
       "3    If Corona has a Virus?  I'm a dead man..  pic....\n",
       "4    Corona Beer claims a conspiracy is behind the ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('datasets/data.json') as f:\n",
    "    data = json.load(f)\n",
    "data_list = []\n",
    "for item in data:\n",
    "    data_list.append(item['text'])\n",
    "data_series = pd.Series(data_list)\n",
    "data_series.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = English()\n",
    "def tokenize(text):\n",
    "    lda_tokens = []\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace():\n",
    "            continue\n",
    "        elif token.like_url:\n",
    "            pass\n",
    "        elif token.orth_.startswith('@'):\n",
    "            pass\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens\n",
    "\n",
    "def get_lemma(word):\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemma\n",
    "\n",
    "def get_lemma2(word):\n",
    "    return WordNetLemmatizer().lemmatize(word)\n",
    "\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text_for_lda(text):\n",
    "    tokens = tokenize(text)\n",
    "    tokens = [token for token in tokens if len(token) > 4]\n",
    "    tokens = [token for token in tokens if token not in en_stop]\n",
    "    tokens = [get_lemma(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []\n",
    "\n",
    "for line in data_list:\n",
    "    tokens = prepare_text_for_lda(line)\n",
    "    if random.random() > .99:\n",
    "        text_data.append(tokens)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(text_data)\n",
    "corpus = [dictionary.doc2bow(text) for text in text_data]\n",
    "pickle.dump(corpus, open('artifacts/corpus.pkl', 'wb'))\n",
    "dictionary.save('artifacts/dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.061*\"virus\" + 0.057*\"corona\" + 0.013*\"drink\" + 0.011*\"infect\" + 0.010*\"thought\" + 0.010*\"come\" + 0.009*\"wearing\" + 0.008*\"everyone\" + 0.008*\"america\" + 0.008*\"cough\"')\n",
      "(1, '0.112*\"corona\" + 0.104*\"virus\" + 0.012*\"disease\" + 0.010*\"chinese\" + 0.010*\"china\" + 0.009*\"horrible\" + 0.009*\"south\" + 0.009*\"sorry\" + 0.008*\"alarm\" + 0.008*\"please\"')\n",
      "(2, '0.092*\"virus\" + 0.092*\"corona\" + 0.026*\"china\" + 0.014*\"coronavirus\" + 0.013*\"spreading\" + 0.012*\"crown\" + 0.011*\"hospital\" + 0.009*\"chinese\" + 0.009*\"outbreak\" + 0.008*\"quarantine\"')\n",
      "(3, '0.095*\"corona\" + 0.083*\"virus\" + 0.014*\"wuhan\" + 0.013*\"hate\" + 0.012*\"pandemic\" + 0.010*\"take\" + 0.009*\"coronavirus\" + 0.009*\"outbreak\" + 0.009*\"update\" + 0.009*\"video\"')\n",
      "(4, '0.113*\"virus\" + 0.089*\"corona\" + 0.014*\"people\" + 0.013*\"worst\" + 0.013*\"first\" + 0.012*\"hate\" + 0.009*\"call\" + 0.009*\"think\" + 0.009*\"transport\" + 0.008*\"china\"')\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 5\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=50,  alpha=80)\n",
    "ldamodel.save('artifacts/model.gensim')\n",
    "topics = ldamodel.print_topics(num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.061*\"virus\" + 0.057*\"corona\" + 0.013*\"drink\"'), (1, '0.112*\"corona\" + 0.104*\"virus\" + 0.012*\"disease\"'), (2, '0.092*\"virus\" + 0.092*\"corona\" + 0.026*\"china\"'), (3, '0.095*\"corona\" + 0.083*\"virus\" + 0.014*\"wuhan\"'), (4, '0.113*\"virus\" + 0.089*\"corona\" + 0.014*\"people\"')]\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topics(num_topics=5, num_words=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -6.513059028921256\n",
      "\n",
      "Coherence Score:  0.6518706496073154\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "print('\\nPerplexity: ', ldamodel.log_perplexity(corpus))\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=ldamodel, texts=text_data, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary.load('artifacts/dictionary.gensim')\n",
    "corpus = pickle.load(open('artifacts/corpus.pkl', 'rb'))\n",
    "lda = gensim.models.ldamodel.LdaModel.load('artifacts/model.gensim')\n",
    "lda_display = pyLDAvis.gensim.prepare(lda, corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
